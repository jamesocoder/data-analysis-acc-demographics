{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef635ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up environment and define shape of data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# List of columns to analyze\n",
    "# Note that pandas will make any duplicate column names unique by appending a sequence number\n",
    "# to subsequent occurences of them when importing said data\n",
    "# (e.g. HMS Rank, HMS Rank.1, HMS Rank.2, etc.)\n",
    "SCHEMA = {\n",
    "    '1. Sex assigned at birth': 'string',\n",
    "    '2. Gender Identity': 'string',\n",
    "    'Black or African American': 'string',\n",
    "    'Hispanic or Latino': 'string',\n",
    "    'American Indian or Alaskan Native': 'string',\n",
    "    'Native Hawaiian and other Pacific Islander': 'string',\n",
    "    'Cambodian or Laotian': 'string',\n",
    "    'None': 'string',\n",
    "    'Prefer not to answer': 'string',\n",
    "    '4. Identification as ': 'string',\n",
    "    '5. Requirement for workplace accommodations: (Reasonable accommodations in the workplace support people with disability and/or chronic health conditions in performing their jobs.) If you would like more information about obtaining accommodations, contact MGH OHS.': 'string',\n",
    "    '1. Are you considering or engaging in the process of retirement? ': 'string',\n",
    "    '2. Are you interested in learning more about HMS promotions and discussing advancement on the HMS ladder? ': 'string',\n",
    "    'MD': 'string',\n",
    "    'MBChB': 'string',\n",
    "    'DO': 'string',\n",
    "    'PhD': 'string',\n",
    "    'DPhil': 'string',\n",
    "    'Sci D': 'string',\n",
    "    'RDN': 'string',\n",
    "    'MS': 'string',\n",
    "    'MSN': 'string',\n",
    "    'MPH': 'string',\n",
    "    'MPA': 'string',\n",
    "    'MBA': 'string',\n",
    "    'Other': 'string',\n",
    "    'i. HMS Rank': 'string',\n",
    "    'ii. Date (yyyy)': 'string',\n",
    "    'i. HMS Rank.1': 'string',\n",
    "    'ii. Date (yyyy).1': 'string',\n",
    "    'i. HMS Rank.2': 'string',\n",
    "    'ii. Date (yyyy).2': 'string',\n",
    "    'i. HMS Rank.3': 'string',\n",
    "    'ii. Date (yyyy).3': 'string',\n",
    "    'i. HMS Rank.4': 'string',\n",
    "    'ii. Date (yyyy).4': 'string',\n",
    "    'i. Job Title': 'string',\n",
    "    'ii. Date (yyyy).5': 'string',\n",
    "    'i. Job Title.1': 'string',\n",
    "    'ii. Date (yyyy).6': 'string',\n",
    "    'i. Job Title.2': 'string',\n",
    "    'ii. Date (yyyy).7': 'string',\n",
    "    'i. Job Title.3': 'string',\n",
    "    'ii. Date (yyyy).8': 'string',\n",
    "    'i. Job Title.4': 'string',\n",
    "    'ii. Date (yyyy).9': 'string',\n",
    "}\n",
    "\n",
    "# Column label capitalization is inconsistent between data sets\n",
    "# Convert all names to lowercase\n",
    "SCHEMA = {key.lower(): val for key, val in SCHEMA.items()}\n",
    "\n",
    "# Store a list of column labels for easier reference\n",
    "COLUMNS = list(SCHEMA.keys())\n",
    "\n",
    "# Create scaffolding for DataFrame that will house concatenated datasets\n",
    "df = pd.DataFrame(columns=COLUMNS).astype(SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets into memory\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "for filepath in Path(\"./data\").iterdir():\n",
    "    if filepath.is_file():\n",
    "        print(f\"Importing {filepath}\")\n",
    "        rawDf = pd.read_excel(\n",
    "            filepath,\n",
    "            header=0,\n",
    "            engine=\"openpyxl\"\n",
    "        )\n",
    "        # Convert raw column names to lowercase\n",
    "        rawDf.rename(columns=str.lower, inplace=True)\n",
    "        # Select only the COLUMNS we are interested in\n",
    "        rawDf = rawDf.filter(items=COLUMNS)\n",
    "        # Clear out blank rows\n",
    "        trimmedDf = rawDf.dropna(how='all')\n",
    "        print(f\"{rawDf.shape[0] - trimmedDf.shape[0]} blank rows dropped.  Remaining rows: {trimmedDf.shape[0]}.\")\n",
    "        # Append rows to main DataFrame\n",
    "        initial = df.shape[0]\n",
    "        df = pd.concat([df, trimmedDf], ignore_index=True)\n",
    "        print(f\"Starting df record count: {initial}\\nAdded records: {trimmedDf.shape[0]}\\nEnding df record count: {df.shape[0]}\\n\")\n",
    "        del rawDf, trimmedDf, initial\n",
    "\n",
    "del Path, filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a887d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
